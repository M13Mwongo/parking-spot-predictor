{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"padding:2rem;font-size:100%;text-align:left;display:fill;border-radius:0.25rem;overflow:hidden;background-image: url(https://images.pexels.com/photos/2860804/pexels-photo-2860804.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1)\"><b><span style='color:grey'> PARKING ANALYSIS PREDICTOR</span></b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a collaborative group project done during Phase 5 of Moringa School's Data Science program. The team members of this group include:\n",
    "1. [Ezra Kipchirchir](https://github.com/dev-ezzy)\n",
    "2. [Grace Mutuku](https://github.com/GraceKoki)\n",
    "3. [Joy Ogutu](https://github.com/Ogutu01)\n",
    "4. [Mary Gaceri](https://github.com/MaryGaceri)\n",
    "5. [Mwiti Mwongo](https://github.com/M13Mwongo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"padding:2rem;font-size:80%;text-align:left;display:fill;border-radius:0.25rem;overflow:hidden;background-image: url(https://images.pexels.com/photos/2860804/pexels-photo-2860804.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1)\"><b><span style='color:white'> Problem statement</span></b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traffic is a nightmare, am I right? You canâ€™t drive anywhere without being stuck in traffic for a while, especially in Nairobi. What makes it worse is that a lot of times during high-traffic periods, such as the mornings and evenings, there is a high likelihood of missing out on your desired parking spot that is near your office, especially when looking at county-run parking.\n",
    "This application hopes to predict the parking patterns and likelihood of having available parking spots in certain areas at a given time of the day.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"padding:2rem;font-size:80%;text-align:left;display:fill;border-radius:0.25rem;overflow:hidden;background-image: url(https://images.pexels.com/photos/2860804/pexels-photo-2860804.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1)\"><b><span style='color:white'> Objectives</span></b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style='display:flex;align-items:center;flex-direction:row'><hr style='background-color:#d4ff00;height:35px;width:4px;margin:0 1rem 0 0;border-radius:2rem'/><span>Main Objective:</span></div>\n",
    "\n",
    "- Predict the availability of parking in a given area in Nairobi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"padding:2rem;font-size:80%;text-align:left;display:fill;border-radius:0.25rem;overflow:hidden;background-image: url(https://images.pexels.com/photos/2860804/pexels-photo-2860804.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1)\"><b><span style='color:white'>Proposed Solution</span></b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we created a model that would predict the availability of parking spots across Nairobi. Our procedure for doing this is as follows, starting with the data sourcing and culminating in the model creation and deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style='display:flex;align-items:center;flex-direction:row'><hr style='background-color:#d4ff00;height:35px;width:4px;margin:0 1rem 0 0;border-radius:2rem'/><span>**0. Preliminaries**</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <div style='display:flex;align-items:center;flex-direction:row'><hr style='background-color:#9DF7E5;height:35px;width:3px;margin:0 1rem 0 0;border-radius:2rem'/><span>**a) Imports & OOP**</span></div>\n",
    "\n",
    "The necessary libraries were first imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "# Basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import requests\n",
    "import json\n",
    "from io import StringIO\n",
    "from datetime import datetime, timedelta\n",
    "from requests import api\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.pylab import rcParams\n",
    "import time\n",
    "\n",
    "# Modeling libraries\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.arima.model import ARIMA        \n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import acf, pacf, adfuller\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "from sklearn.model_selection import TimeSeriesSplit \n",
    "from pmdarima import auto_arima      \n",
    "\n",
    "from prophet import Prophet \n",
    "\n",
    "#Model deployment libraries\n",
    "import joblib    \n",
    "\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Custom Options for displaying rows.\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns',100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In object-oriented programming (OOP), classes serve as blueprints, dividing code into modular components that contain data and actions. They encourage encapsulation, abstraction, and inheritance in code, making it more modular, readable, and manageable. Classes offer an organized way to developing and implementing code, promoting clarity and efficiency in software development.\n",
    "\n",
    "Consequently, the following classes were implemented and defined below:\n",
    "1. Data Sourcing\n",
    "2. Data Preprocessing\n",
    "3. Data Analysis\n",
    "4. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSourcing:\n",
    "  def __init__(self,carparks_file_path,carpark_structure_file_path,carpark_history_file_path):\n",
    "    \n",
    "    df_carparks = pd.read_json(carparks_file_path)\n",
    "    df_carpark_details = pd.read_json(carpark_structure_file_path)\n",
    "    df_carpark_history = pd.read_json(carpark_history_file_path)\n",
    "    \n",
    "    self.carparks_all = df_carparks\n",
    "    self.carpark_details = df_carpark_details\n",
    "    self.carpark_history = df_carpark_history\n",
    "  \n",
    "  def get_carparks(self):\n",
    "    \"\"\"\n",
    "    Get the carparks from the instance variable `carparks_all`.\n",
    "    \n",
    "    Returns:\n",
    "        list: List of carparks.\n",
    "    \"\"\"\n",
    "    return self.carparks_all\n",
    "  def get_carpark_details(self):\n",
    "    \"\"\"\n",
    "    Get the carpark details.\n",
    "\n",
    "    Returns:\n",
    "        dict: The carpark details.\n",
    "    \"\"\"\n",
    "    return self.carpark_details\n",
    "  def get_carpark_history(self):\n",
    "    \"\"\"\n",
    "    Get the car park history.\n",
    "\n",
    "    Returns:\n",
    "        carpark_history: The history of the car park.\n",
    "    \"\"\"\n",
    "    return self.carpark_history\n",
    "  \n",
    "class DataPreprocessing:\n",
    "  pass\n",
    "\n",
    "class DataAnalysis:\n",
    "  pass\n",
    "\n",
    "class Modelling:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <div style='display:flex;align-items:center;flex-direction:row'><hr style='background-color:#9DF7E5;height:35px;width:3px;margin:0 1rem 0 0;border-radius:2rem'/><span>**b) The Process of Fetching Data**</span></div>\n",
    "\n",
    "Our data was sourced from the Transport for New South Wales(TfNSW) website, more speficially, from their [Car Park API](https://opendata.transport.nsw.gov.au/dataset/car-park-api)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The API - whose base URL was `https://api.transport.nsw.gov.au/v1/carpark` - had two endpoints:\n",
    "1. `{baseURL}?facility={facility_id}` - Containts one optional variable ***facility_id***. Returns occupancy details of a car park based on a facility ID. If the facility ID specified, a list of facility names with their ID will be returned.\n",
    "2. `{baseURL}}/history?facility={facility_id}&eventdate={date_in_question}` - Contains two mandatory variables, ***facility_id*** and ***date_in_question*** formatted as *YYYY-MM-DD*. Returns historical occupancy details of a car park based on a facility ID\n",
    "and event date. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our intention was to use this API to fetch six months' worth of historical parking data. An extensive time period would lead to a proper understanding of parking habits across a wide array of conditions while factoring in social events, public holidays, school holidays and even leave days of employees.\n",
    "\n",
    "The team came up with code to automatically make requests to the API, and save this information in a dataframe. However, after further study of the API's structure and the data being received, the team saw it best to have these requests made once and the resulting data stored in json files, which can be read by pandas.\n",
    "\n",
    "The function below was used to retrieve car park data from the TfNSW API and saves it to a JSON file. It will then read the JSON file into a dataframe, rename the columns as they come with no name from the API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "def get_carparks_list():\n",
    "  dotenv.load_dotenv('.env')\n",
    "  # path to json file created/saved\n",
    "  carparks_file_path = './data/carparks_original.json'\n",
    "  # Delete any existing file at carparks path\n",
    "  os.remove(carparks_file_path) if os.path.exists(carparks_file_path) else None\n",
    "\n",
    "  # Creating header for request\n",
    "  headers = {\n",
    "      \"Authorization\": f\"apikey {os.environ.get('apikey')}\"\n",
    "  }\n",
    "  # Specifying url to get carparks\n",
    "  url_carparks = 'https://api.transport.nsw.gov.au/v1/carpark'\n",
    "\n",
    "  list_of_carparks = requests.get(url_carparks, headers=headers).json()\n",
    "\n",
    "  df_carparks = pd.DataFrame.from_dict(list_of_carparks, orient='index')\n",
    "  # Resetting the index to label the columns afterwards\n",
    "  df_carparks = df_carparks.reset_index()\n",
    "  df_carparks.columns = ['facility_id', 'CarParkName']\n",
    "\n",
    "  # Deleting old file\n",
    "  os.remove(carparks_file_path) if os.path.exists(carparks_file_path) else None\n",
    "\n",
    "  # Creating new file with updated column titles\n",
    "  pd.DataFrame.to_json(df_carparks, carparks_file_path)\n",
    "\n",
    "  print('File created and updated successfully.')\n",
    "  return\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, despite having a complete list of all the carparks, not all the carparks will be used. As per the API, there are certain carparks that will not have accurate information for a certain column which will be needed. As such, there is no need to keep records for these carparks and they will be removed from the `carparks_original.json` file. \n",
    "\n",
    "These carparks have the facility_ids ranging between `486` and `490` (inclusive). The function below was used to remove these records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Dropping rows 28,29,30,31,32\n",
    "df_carpark_details.drop(index=[28,29,30,31,32],inplace=True)\n",
    "\n",
    "# Resetting the index\n",
    "df_carpark_details.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# Sorting by facility_id\n",
    "df_carpark_details.sort_values(by='facility_id',inplace=True)\n",
    "df_carpark_details\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having the names of the various facilites, the structure of each of the carparks was investigated. It was noted that each car park can have a different configuration, where each facility may have one or more car parks, and each car park may have one or more zones as depicted below.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src='./images/carpark_structure.png' alt='Carpark structure'>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing this, the function below was created to fetch the individual details of the carparks - using the JSON file just created - to properly scrutinise their structure. This would then be saved in its own JSON file named `carpark_structure.json` for future reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "def get_carpark_structure(path_to_carpark_json_file):\n",
    "  # Delete file found at same path\n",
    "  os.remove('./data/carpark_structure.json') if os.path.exists('./data/carpark_structure.json') else None\n",
    "  # Add file to dataframe\n",
    "  df_carparks = pd.read_json(path_to_carpark_json_file)\n",
    "  # Initialise array that will hold information\n",
    "  carpark_details_array = []\n",
    "\n",
    "  # Loop through carparks to get information\n",
    "  for index, row in df_carparks.iterrows():\n",
    "    facility = row['facility_id']\n",
    "    url = f'https://api.transport.nsw.gov.au/v1/carpark?facility={facility}'\n",
    "\n",
    "    # Creating header for request\n",
    "    headers = {\n",
    "        \"Authorization\": f\"apikey {os.environ.get('apikey')}\"\n",
    "    }\n",
    "    # Make request\n",
    "    response = requests.get(url, headers=headers).json()\n",
    "\n",
    "    # Add to array\n",
    "    carpark_details_array.append(response)\n",
    "\n",
    "  # Store information in JSON file\n",
    "  with open('./data/carpark_structure.json', 'w') as f:\n",
    "    json.dump(carpark_details_array, f)\n",
    "  # Create dataframe and return it\n",
    "  return pd.DataFrame(carpark_details_array)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having done that, a new function - named `date_getter` - was created to give a list of all the days in a given time period. This would be useful as carpark history for each of the carparks within a given time delta would be needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "def date_getter(td):\n",
    "    \"\"\"\n",
    "    Generate a list of dates based on the input time delta.\n",
    "\n",
    "    Args:\n",
    "    td (timedelta): The time delta to subtract from the cutoff date.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of dates in the format \"YYYY-MM-DD\".\n",
    "    \"\"\"\n",
    "    # Array that stores the dates to be searched for\n",
    "    date_period_list = []\n",
    "\n",
    "    # The last date to be searched for\n",
    "    cutoff_date = datetime(2023, 12, 31)\n",
    "    target_date = cutoff_date - td\n",
    "\n",
    "    # Ensure that records of each day are obtained\n",
    "    delta = timedelta(days=1)\n",
    "\n",
    "    while target_date <= cutoff_date:\n",
    "        date_period_list.append(target_date.strftime(\"%Y-%m-%d\"))\n",
    "        target_date += delta\n",
    "\n",
    "    return date_period_list\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a date function, a new function (`get_carpark_history`) was made to fetch the carpark history of a particular facility across a range of dates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def get_carpark_history(facility, dates_array):\n",
    "    \"\"\"\n",
    "    Get carpark history data for a specific facility and dates.\n",
    "\n",
    "    Args:\n",
    "    facility (str): The name of the carpark facility.\n",
    "    dates_array (list): List of dates for which to retrieve carpark history data.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame containing the carpark history data.\n",
    "    \"\"\"\n",
    "    # Initialize data array\n",
    "    data_array = []\n",
    "\n",
    "    # Define the path for the JSON file\n",
    "    json_file_path = f\"./data/carpark history/facility_{facility}.json\"\n",
    "\n",
    "    # Set the request header\n",
    "    headers = {\n",
    "        \"Authorization\": f\"apikey {os.environ.get('apikey')}\"\n",
    "    }\n",
    "\n",
    "    # Delete the file if it exists\n",
    "    if os.path.exists(json_file_path):\n",
    "        os.remove(json_file_path)\n",
    "\n",
    "    # Make a request for each date and aggregate the data\n",
    "    for date in dates_array:\n",
    "        url = f'https://api.transport.nsw.gov.au/v1/carpark/history?facility={facility}&eventdate={date}'\n",
    "        response = requests.get(url, headers=headers).json()\n",
    "\n",
    "        if data_array == []:\n",
    "            data_array = response\n",
    "        else:\n",
    "            data_array = data_array + response\n",
    "\n",
    "    # Save the data to a JSON file\n",
    "    with open(json_file_path, 'w') as f:\n",
    "        json.dump(data_array, f)\n",
    "\n",
    "    # Read the JSON file\n",
    "    with open(json_file_path) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Convert the read data into a pandas DataFrame\n",
    "    return pd.DataFrame(data)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style='display:flex;align-items:center;flex-direction:row'><hr style='background-color:#d4ff00;height:35px;width:4px;margin:0 1rem 0 0;border-radius:2rem'/><span>**1. Data Sourcing:**</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data was sourced from the Transport for New South Wales(TfNSW) website, more speficially, from their [Car Park API](https://opendata.transport.nsw.gov.au/dataset/car-park-api).\n",
    "\n",
    "The API - whose base URL was `https://api.transport.nsw.gov.au/v1/carpark` - had two endpoints:\n",
    "1. `{baseURL}?facility={facility_id}` - Containts one optional variable ***facility_id***. Returns occupancy details of a car park based on a facility ID. If the facility ID specified, a list of facility names with their ID will be returned.\n",
    "2. `{baseURL}}/history?facility={facility_id}&eventdate={date_in_question}` - Contains two mandatory variables, ***facility_id*** and ***date_in_question*** formatted as *YYYY-MM-DD*. Returns historical occupancy details of a car park based on a facility ID\n",
    "and event date. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data was sourced over a 3 month period, from the beginning of October 2023 to 31st December 2023. A loop was created for each facility using the given date range, and the `get_carpark_history` function was run within that loop. The respective files that were saved contained the parking history of that facility for the 3-month time period (found in *./data/carpark_history_3_months/facility_<<facility_id>>*). However, in a bid to simplify the starting point and to ensure that one dataframe is used as our starting point, the code below was implemented to read all the data from the various JSON files and put it in one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = './data/carpark_history_3_months'\n",
    "df= pd.DataFrame()\n",
    "\n",
    "for facility_id in range(6, 34):\n",
    "  # Retrieve file\n",
    "  file = f\"{folder_path}/facility_{facility_id}.json\"\n",
    "\n",
    "  # Read file\n",
    "  with open(file) as f:\n",
    "    data = json.load(f)\n",
    "    df_temp = pd.DataFrame(data)\n",
    "    df_combined = pd.concat([df_combined, df], ignore_index=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style='display:flex;align-items:center;flex-direction:row'><hr style='background-color:#d4ff00;height:35px;width:4px;margin:0 1rem 0 0;border-radius:2rem'/><span>**2. Data Understanding:**</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The identification, gathering, and cursory analysis of the data in this part will be carried out by:\n",
    "\n",
    "- Gathering preliminary data, which has been put into a JSON file.\n",
    "- Describing the data that we have at our disposal.\n",
    "- Looking for patterns and correlations in the data.\n",
    "- Confirming the accuracy of the data.\n",
    "\n",
    "Firstly, to have access the data, we shall pass the respective paths to the data sourcing class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sourcing = DataSourcing(carpark_history_file_path='./carpark_history_facility_14.json',carpark_structure_file_path='./data/carpark_structure.json',carparks_file_path='./data/carparks_original.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style='display:flex;align-items:center;flex-direction:row'><hr style='background-color:#d4ff00;height:35px;width:4px;margin:0 1rem 0 0;border-radius:2rem'/><span>**3. Data Preprocessing:**</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style='display:flex;align-items:center;flex-direction:row'><hr style='background-color:#d4ff00;height:35px;width:4px;margin:0 1rem 0 0;border-radius:2rem'/><span>**4. Data Handling**</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style='display:flex;align-items:center;flex-direction:row'><hr style='background-color:#d4ff00;height:35px;width:4px;margin:0 1rem 0 0;border-radius:2rem'/><span>**5. Explorative Data Analysis & Visualisation**</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style='display:flex;align-items:center;flex-direction:row'><hr style='background-color:#d4ff00;height:35px;width:4px;margin:0 1rem 0 0;border-radius:2rem'/><span>**6. Modelling**</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style='display:flex;align-items:center;flex-direction:row'><hr style='background-color:#d4ff00;height:35px;width:4px;margin:0 1rem 0 0;border-radius:2rem'/><span>**7. Deployment**</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style='display:flex;align-items:center;flex-direction:row'><hr style='background-color:#d4ff00;height:35px;width:4px;margin:0 1rem 0 0;border-radius:2rem'/><span>**8. Conclusion**</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"padding:2rem;font-size:80%;text-align:left;display:fill;border-radius:0.25rem;overflow:hidden;background-image: url(https://images.pexels.com/photos/2860804/pexels-photo-2860804.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1)\"><b><span style='color:white'>Conclusion</span></b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mwiti-base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
<<<<<<< HEAD
   "version": "3.8.5"
=======
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
>>>>>>> 87fffbfb92f3a7f79a6a4b64e0d83cbb61b2ee29
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
