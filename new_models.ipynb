{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# import xgboost as xgb\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# from fbprophet import Prophet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pmdarima import auto_arima\n",
    "import xgboost as xgb\n",
    "from datetime import timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelling_data = pd.read_parquet(\"modelling_data.parquet\")\n",
    "#inspecting the head\n",
    "modelling_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBOOST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_dummies = pd.get_dummies(modelling_data[['day_of_week', 'time_category', 'month', 'is_holiday']],\n",
    "                            columns=[\"day_of_week\", \"time_category\", 'month', 'is_holiday'], prefix= [\"day_of_the_week\", \"time_period\", 'month', 'is_holiday'],\n",
    "                            sparse= False, drop_first= True)\n",
    "#converting dummies to numerical\n",
    "xg_dummies = xg_dummies.astype(int)\n",
    "#joining the dummies and original df\n",
    "xg_encoded = pd.concat( [modelling_data, xg_dummies] ,axis=1)\n",
    "#dropping cat columns\n",
    "xg_encoded.drop([\"longitude\", \"latitude\", \"occupancy\", \"facility_name\", \"month\", \"time_category\", \"day_of_week\", \"is_holiday\"], axis= 1, inplace= True)\n",
    "\n",
    "xg_encoded = xg_encoded.set_index(\"datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_grouped = xg_encoded.groupby(\"facility_id\")\n",
    "xg_grouped.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store XGBoost models for each parking lot\n",
    "xg_models = {}\n",
    "\n",
    "# Train a model for each parking lot\n",
    "for facility_id, group_data in xg_grouped:\n",
    "    # Split the data into features and target variable\n",
    "    X = group_data.drop(columns=[\"parking_availability\"], axis=1)\n",
    "    y = group_data[\"parking_availability\"]\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create an XGBoost model\n",
    "    xg_model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "    # Train the model\n",
    "    xg_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    # group_data[\"prediction\"] = xg_model.predict(X_test)\n",
    "    predictions = xg_model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    rmse = sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    print(f'Mean Squared Error for {facility_id}: {mse}')\n",
    "    print(f'Root Mean Squared Error for {facility_id}: {rmse}')\n",
    "    print(f'Mean Absolute Error for {facility_id}: {mae}')\n",
    "    \n",
    "    # Store the trained model in the dictionary\n",
    "    xg_models[facility_id] = xg_model\n",
    "\n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.plot(X_test.index, y_test, label='Actual', marker='o')\n",
    "    plt.plot(X_test.index, predictions, label='Predicted', marker='o')\n",
    "    plt.title(f'Actual vs Predicted for {facility_id}')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Parking Availability')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = { \n",
    "    \"learning_rate\": [0.01, 0.2],\n",
    "    \"max_depth\": [5, 6, 7],\n",
    "    \"gamma\": [0.1, 0.2],\n",
    "    \"reg_lambda\": [0.01,  0.1],\n",
    "    \"reg_alpha\": [0, 0.01, 0.1, 0.2],\n",
    "    \"n_estimators\": [30, 50]\n",
    "}\n",
    "class XGBoostTimeSeriesModel:\n",
    "    def __init__(self, param_grid, target_variable='parking_availability', cv=3, n_jobs=-1):\n",
    "        self.param_grid = param_grid\n",
    "        self.target_variable = target_variable\n",
    "        self.cv = cv\n",
    "        self.n_jobs = n_jobs\n",
    "        self.models = {}\n",
    "\n",
    "    def _get_features_target(self, group_data):\n",
    "        X = group_data.drop(columns=[self.target_variable, \"facility_name\"], axis=1)\n",
    "        y = group_data[self.target_variable]\n",
    "        return X, y\n",
    "\n",
    "    def train_models(self, xg_grouped):\n",
    "        for facility_name, group_data in xg_grouped:\n",
    "            X, y = self._get_features_target(group_data)\n",
    "\n",
    "            # Create an XGBoost model\n",
    "            xg_model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "            # Perform GridSearchCV\n",
    "            grid_search = GridSearchCV(xg_model, param_grid=self.param_grid, cv=self.cv, n_jobs=self.n_jobs)\n",
    "            grid_search.fit(X, y)\n",
    "\n",
    "            # Get the best hyperparameters\n",
    "            best_params = grid_search.best_params_\n",
    "            print(f'Best Hyperparameters for {facility_name}: {best_params}')\n",
    "\n",
    "            # Use the best model from GridSearchCV\n",
    "            best_model = grid_search.best_estimator_\n",
    "\n",
    "            # Train the model\n",
    "            best_model.fit(X, y)\n",
    "\n",
    "            # Store the trained model in the dictionary\n",
    "            self.models[facility_name] = best_model\n",
    "\n",
    "    def predict_and_plot(self, xg_grouped):\n",
    "        predictions_df = pd.DataFrame()  # Initialize the DataFrame to store predictions\n",
    "\n",
    "        for facility_name, model in self.models.items():\n",
    "            # Get the last available data for each facility\n",
    "            last_data = xg_grouped.get_group(facility_name).tail(1).drop(columns=[\"parking_availability\"])\n",
    "\n",
    "            # Make predictions for the next time period\n",
    "            facility_predictions = model.predict(last_data)\n",
    "\n",
    "            # Add 'prediction' column to the predictions DataFrame\n",
    "            predictions_df = pd.concat([predictions_df, pd.DataFrame({\n",
    "                'facility_name': [facility_name] * len(facility_predictions),\n",
    "                'prediction': facility_predictions\n",
    "                })])\n",
    "\n",
    "        # Merge predictions with the original DataFrame based on the 'facility_name'\n",
    "        xg_grouped_predictions = pd.merge(xg_grouped, predictions_df, on='facility_name', how='left')\n",
    "\n",
    "        # Plot actual vs predicted values for each facility\n",
    "        for facility_name, group_data in xg_grouped_predictions.groupby('facility_name'):\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.plot(group_data.index, group_data[self.target_variable], label='Actual', marker='o')\n",
    "            plt.plot(group_data.index, group_data['prediction'], label='Predicted', marker='o')\n",
    "            plt.title(f'Actual vs Predicted for {facility_name}')\n",
    "            plt.xlabel('Date')\n",
    "            plt.ylabel('Parking Availability')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "    \n",
    "    def predict_and_plot(self, xg_grouped):\n",
    "        predictions_df = pd.DataFrame()  # Initialize the DataFrame to store predictions\n",
    "\n",
    "        for facility_name, model in self.models.items():\n",
    "            # Get the last available data for each facility\n",
    "            last_data = xg_grouped.get_group(facility_name).tail(1).drop(columns=[\"parking_availability\"])\n",
    "\n",
    "            # Make predictions for the next time period\n",
    "            facility_predictions = model.predict(last_data)\n",
    "\n",
    "            # Add 'prediction' column to the predictions DataFrame\n",
    "            predictions_df = pd.concat([predictions_df, pd.DataFrame({\n",
    "                'facility_name': [facility_name] * len(facility_predictions),\n",
    "                'prediction': facility_predictions\n",
    "            })])\n",
    "\n",
    "\n",
    "\n",
    "        # Transform the groupby object to a DataFrame\n",
    "        xg_grouped_df = xg_grouped.transform('last').reset_index()\n",
    "\n",
    "        # Merge predictions with the original DataFrame based on the 'facility_name'\n",
    "        xg_grouped_predictions = pd.merge(xg_grouped_df, predictions_df, on='facility_name', how='left')\n",
    "\n",
    "        # Plot actual vs predicted values for each facility\n",
    "        for facility_name, group_data in xg_grouped_predictions.groupby('facility_name'):\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.plot(group_data.index, group_data[self.target_variable], label='Actual', marker='o')\n",
    "            plt.plot(group_data.index, group_data['prediction'], label='Predicted', marker='o')\n",
    "            plt.title(f'Actual vs Predicted for {facility_name}')\n",
    "            plt.xlabel('Date')\n",
    "            plt.ylabel('Parking Availability')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        \n",
    "\n",
    "\n",
    "# # Example usage:\n",
    "xg_model = XGBoostTimeSeriesModel(param_grid, target_variable= \"parking_availability\", cv=3, n_jobs= -1)\n",
    "xg_model.train_models(xg_grouped)\n",
    "xg_model.predict_and_plot(xg_grouped)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ezra-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
