{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing all relevant modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "# Basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from io import StringIO\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.pylab import rcParams\n",
    "import time\n",
    "\n",
    "# Modeling libraries\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.arima.model import ARIMA        \n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import acf, pacf, adfuller\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "from sklearn.model_selection import TimeSeriesSplit \n",
    "from pmdarima import auto_arima      \n",
    "\n",
    "from prophet import Prophet \n",
    "\n",
    "#Model deployment libraries\n",
    "import joblib    \n",
    "\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Custom Options for displaying rows.\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns',100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading sample data from TfNSW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"data/NSW response - 2022-03-13.json\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at dataframe columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And dataframe info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values in the time column are given in seconds since year 2000. Converting it to more meaningful data that can be interpreted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date_time(message_date):\n",
    "  date = message_date.split('T')[0]\n",
    "  time = message_date.split('T')[1]\n",
    "  return date,time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "\n",
    "df_copy[['date','time']] = df['MessageDate'].apply(extract_date_time).apply(pd.Series)\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating column with day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['day_of_week'] = pd.to_datetime(df_copy['date']).apply(lambda x: x.strftime('%A'))\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reordering columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_copy[['tsn','day_of_week','date','time','spots','zones','ParkID','occupancy','MessageDate','facility_id','facility_name','tfnsw_facility_id']]\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping columns not needed now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.drop(['tfnsw_facility_id', 'ParkID','MessageDate', 'facility_id'], axis=1, inplace=True)\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the zones column to its own dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = pd.DataFrame(columns=['spots','zone_id','zone_name','parent_zone_id','occupancy'])\n",
    "rename_format = {\n",
    "    0:'spots',\n",
    "    1:'zone_id',\n",
    "    2:'zone_name',\n",
    "    3:'parent_zone_id',\n",
    "    4:'occupancy loops',\n",
    "    5:'occupancy total',\n",
    "    6:'occupancy monthlies',\n",
    "    7:'occupancy open_gate',\n",
    "    8:'occupancy transients'}\n",
    "\n",
    "\n",
    "\n",
    "for key,value in df['zones'].items():    \n",
    "    # Normalize values in each record in zones column\n",
    "    val = pd.json_normalize(value)\n",
    "    \n",
    "    # Convert it to a dataframe\n",
    "    temp_holder = pd.DataFrame.from_dict(val.values)\n",
    "    # Renaming columns\n",
    "    temp_holder.rename(mapper=rename_format, axis=1, inplace=True)\n",
    "    # merge it with main dataframe\n",
    "    df_zones = pd.concat([df_zones, temp_holder], ignore_index=True)\n",
    "\n",
    "df_zones.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping unneccessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones.drop(['parent_zone_id','occupancy','occupancy loops','occupancy monthlies','occupancy open_gate','occupancy transients'], axis=1, inplace=True)\n",
    "df_zones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_occupancy = pd.DataFrame(\n",
    "    columns=['spots', 'zone_id', 'zone_name', 'parent_zone_id', 'occupancy'])\n",
    "rename_format = {\n",
    "    0: 'spots',\n",
    "    1: 'zone_id',\n",
    "    2: 'zone_name',\n",
    "    3: 'parent_zone_id',\n",
    "    4: 'occupancy_loops',\n",
    "    5: 'occupancy_total',\n",
    "    6: 'occupancy_monthlies',\n",
    "    7: 'occupancy_open_gate',\n",
    "    8: 'occupancy_transients'}\n",
    "\n",
    "\n",
    "for key, value in df['zones'].items():\n",
    "    # Normalize values in each record in zones column\n",
    "    val = pd.json_normalize(value)\n",
    "\n",
    "    # Convert it to a dataframe\n",
    "    temp_holder = pd.DataFrame.from_dict(val.values)\n",
    "    # Renaming columns\n",
    "    temp_holder.rename(mapper=rename_format, axis=1, inplace=True)\n",
    "    # merge it with main dataframe\n",
    "    df_occupancy = pd.concat([df_occupancy, temp_holder], ignore_index=True)\n",
    "\n",
    "df_occupancy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_occupancy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the two new dataframes to ensure they have the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(0,191):\n",
    "    value_df1 = df_zones.loc[index,'occupancy total']\n",
    "    value_df2 = df_occupancy.loc[index,'occupancy_total']\n",
    "    if value_df1 != value_df2:\n",
    "        print(index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is no index printed, each record has the same value in both dataframes. Thus, only one of them is needed - and will be merged to the main dataframe - while the other will be dropped. Since the name is less misleading, the `df_occupancy` dataframe will be maintained.\n",
    "\n",
    "Before merging it to the main dataframe, unnecessary columns will be dropped. Reordering of columns will also be done before renaming the spots column to something more intuitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dropping rows with null values\n",
    "# df_occupancy.dropna(inplace=True)\n",
    "\n",
    "# Dropping unnecessary columns\n",
    "df_occupancy.drop(['zone_id', 'occupancy_loops', 'parent_zone_id', 'occupancy',\n",
    "                  'occupancy_monthlies','occupancy_open_gate','occupancy_transients'], axis=1, inplace=True)\n",
    "# Reordering columns\n",
    "df_occupancy = df_occupancy[['zone_name','spots', 'occupancy_total']]\n",
    "\n",
    "# Renaming the spots column\n",
    "df_occupancy.rename(columns={'spots': 'total_parking_spots'}, inplace=True)\n",
    "\n",
    "df_occupancy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the columns to their respective data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_occupancy['occupancy_total'] = df_occupancy['occupancy_total'].astype(np.int64)\n",
    "df_occupancy['total_parking_spots'] = df_occupancy['total_parking_spots'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_occupancy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going ahead to create a new column `parking_availability` which calculates how many parking spots are available at a given time.\n",
    "\n",
    "It is calculated by subtracting the total from the spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_occupancy['parking_availability'] = df_occupancy['total_parking_spots'] - df_occupancy['occupancy_total']\n",
    "df_occupancy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping unnecessary columns from the main dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.drop(['zones','spots','occupancy'],axis=1,inplace=True)\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging `df_copy` and `df_occupancy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = pd.concat([df_copy,df_occupancy],axis=1)\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mwiti-base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
